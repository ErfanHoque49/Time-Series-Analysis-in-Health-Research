---
title: "Time Series Analysis in Health Research"
subtitle: "Forecasting of Weekly Flu Positive Cases in Canada"
author: "Erfan Hoque \\
  
  Dept. of Community Health and Epidemiology \\
  
  University of Saskatchewan."
  
date: "SEA 24th Annual Symposium Workshop, September 26, 2025"
output:
  pdf_document: default
  html_document:
    keep_md: true
---

We will work in *fpp3* package. Load the library *fpp3*. If *fpp3* package is not installed, then we need to install it first and then load the library. 

```{r setup, error=FALSE, warning=FALSE, message=FALSE}
library(fpp3)
library(dplyr)
library(fable.prophet) # needed for Prophet model
```

This document is intended to serve as a rough template for what we covered in the last lectures on time series analysis in R.

# Google Flu Data

## Data Discription: 

This is Google Flu trend data for Canada (2003-2015). These data are provided by the Statistical Society of Canada (SSC) in 2016 as part of the SSC case study competition. 
link: <https://ssc.ca/en/case-study/can-google-flu-trends-predict-frequency-and-results-tests-influenza-and-other>.

## Google Flu Data Information: 

In 2009-2010, a novel H1N1 influenza virus, often called *swine flu*, caused a global pandemic, which the WHO declared in June 2009 and ended in August 2010.

Google Flu Trends (GFT) was a service that used aggregated Google search query data to estimate the prevalence of influenza-like illness (ILI) in populations, aiming to provide real-time, early warnings for flu outbreaks. It provided estimates of influenza activity for more than 25 countries. The idea behind Google Flu Trends was that, by monitoring millions of usersâ€™ health tracking behaviors online, the large number of Google search queries gathered can be analyzed to reveal if there is the presence of flu-like illness in a population.

While it showed initial promise, GFT was discontinued in 2015 after several years of inaccurate estimates, largely due to problems with its original algorithm, changes to Google's search algorithm, and biases in the data.

Source: <https://en.wikipedia.org/wiki/Google_Flu_Trends>

Frequency: Weekly 

Geography: Canada and Some Provinces

## Set Directory 

To check your current working directory in R, use: ```getwd()```

This will return the path of the directory where R is currently reading and writing files like this

```{r, eval=FALSE}
getwd()
```

## Read Data 

To read a different data you need to change the name of the data based on the data file name. 

```{r}
flu <- read.csv("flu_model.csv")
```

## tisbble objects

We need to create the data in *tisbble* object to use the functions from *fpp3* package.

```{r}
flu_ts <- flu |>
  mutate(week=yearweek(week),
         Date=as.Date(Date)) |>
  as_tsibble(index = week)
flu_ts |>
  head(10) # check first few rows of the data
```

# Time series plot, patterns and decomposition

## Time plot

```{r, fig.height=4, fig.width=8, warning=FALSE}
flu_ts %>% autoplot(FluPos) +
  labs(title = "Weekly flu positive case in Canada",
         y="Number of positive cases")
```

We can see some short trend and seasonality in the mortality rate. 

## Seasonal plots
A seasonal plot is similar to a time plot except that the data are plotted against the individual ``seasons" in which the data were observed. This enables the underlying seasonal pattern to be seen more clearly, and also allows any substantial departures from the seasonal pattern to be easily identified.

```{r, fig.height=4, fig.width=8, warning=FALSE}
flu_ts |>
  gg_season(FluPos)+
      labs(title = "Weekly flu positive case in Canada",
         y="Number of positive cases")+
  guides(color = guide_legend(title = "Year"))
```

## Autocorrelation

When data have a trend, the autocorrelations for small lags tend to be large and positive. When data are seasonal, the autocorrelations will be larger at the seasonal lags (i.e., at multiples of the seasonal frequency). When data are trended and seasonal, we see a combination of these effects.

```{r, fig.height=4, fig.width=8}
flu_ts %>% 
  ACF(FluPos, lag_max = 52) %>% autoplot()
```

## Time series decomposition
STL (Seasonal and Trend decomposition using Loess) is a versatile and robust method for decomposing time series.

```{r}
dcmp <- flu_ts %>%
  model(stl = STL(FluPos))
components(dcmp)
```

### Trend-adjustment

```{r}
flu_ts %>%
  autoplot(FluPos, color='gray') +
  autolayer(components(dcmp), trend, color='#D55E00') +
  labs(y = "Rate", title = "Weekly flu positive case in Canada")
```

### Seasonal-adjustment

```{r}
flu_ts %>%
  autoplot(FluPos, color='gray') +
  autolayer(components(dcmp), season_adjust, color='#0072B2') +
  labs(y = "Rate", title = "Weekly mortality rate in Canada")
```

## Classical Decomposition
The traditional way to do time series decomposition is called `Classical decomposition`. The simplest estimate of the trend-cycle uses *moving averages* which is an average of nearby points.

```{r}
flu_ts_decom <- flu_ts |>
  mutate(
    `3-MA` = slider::slide_dbl(FluPos, mean,
                .before = 1, .after = 1, .complete = TRUE),
    `5-MA` = slider::slide_dbl(FluPos, mean,
                .before = 2, .after = 2, .complete = TRUE)
  )
# plot of 3-MA
flu_ts_decom |>
  autoplot(FluPos) +
  geom_line(aes(y = `3-MA`), colour = "#D55E00")+
  labs(title = "3-MA smoothing")
# plot of 5-MA
flu_ts_decom |>
  autoplot(FluPos) +
  geom_line(aes(y = `5-MA`), colour = "#D55E00")+
  labs(title = "5-MA smoothing")
```

# Forecasting Models

## Simple forecasting methods
The `model()` function trains models to data. We are going to forecast using Mean, Naive and Seasonal Naive method. 

```{r}
flu_fit <-  flu_ts %>%
  model(
    Seasonal_naive = SNAIVE(FluPos),
    Naive = NAIVE(FluPos),
    Mean = MEAN(FluPos)
  )
```

We can now produce forecasts using the fitted models.

```{r}
flu_fc <- flu_fit %>%
  forecast(h = "1 years")

flu_fc %>%
  autoplot(flu_ts, level = NULL) +
  labs(title = "Weekly flu positive case in Canada",
       y = "Number of positive cases") +
  guides(colour = guide_legend(title = "Forecast"))
```

## Residual diagnostics

It is very important to do the residual diagnostic after fitting any model to check whether the residual assumptions have been satisfied or not. 

```{r, warning=FALSE}
fit.naive <- flu_ts %>% model(NAIVE(FluPos))
gg_tsresiduals(fit.naive)
```

Here, based on the plots, we can say the residual assumptions (uncorrelated,
mean zero, constant variance) have not been satisfied for Naive model. 

## Tests for autocorrelation
Moreover, we can do Box-Pierce or Ljung-Box test to see whether the residuals are significantly different from a zero set. 

H\_0: the series is white noise vs H\_1: the series is not white noise.

```{r}
augment(fit.naive) %>%
  features(.resid, ljung_box, lag=10, dof=0)
```

The results are significant (i.e., the p-values are relatively small < 0.05). Thus, we
can conclude that the residuals are distinguishable from a white noise series.

## ARIMA / SARIMA models

Before fitting the ARIMA model, it is important to check the stationary of the data. If the data is non-stationary, then we need to make it stationary using the idea of differencing. Differencing helps to stabilize the mean (one way to make a non-stationary time series stationary).

```{r, fig.height=4, fig.width=8}
flu_ts %>% ACF(FluPos) %>% autoplot() +
    labs(title = "Weekly flu positive in Canada without differencing",
       y = "Number of positive cases")
```

```{r, fig.height=4, fig.width=8}
flu_ts %>% ACF(difference(FluPos)) %>% autoplot() +
    labs(title = "Weekly flu positive case in Canada with differencing",
       y = "Number of positive cases")
```

First order differencing seems make the mortality data stationary. But still there are some pattern left over. 

Now let's fit the ARIMA/SARIMA model. The *ARIMA* frunction form *fpp3* package does everything together (checking for stationarity of the data, doing any differencing if needed and then fitting the model using ARIMA or SARIMA based on data)

```{r}
fit.arima <- flu_ts |>
  model(ARIMA(FluPos))
report(fit.arima)
```

We have SARIMA(1,0,3)(0,0,1)[52] model for this data. 

Let's check the residual.

```{r}
gg_tsresiduals(fit.arima)
```

Here, based on the plots, we can say the residual assumptions (uncorrelated,
mean zero, constant variance) have been satisfied for ARIMA model (still some pick is there!).

```{r}
augment(fit.arima) %>%
  features(.innov, ljung_box, lag = 36, dof=4)
```

The results are not significant (i.e., the p-values are relatively large). Thus, we
can conclude that the residuals are not distinguishable from a white noise series.

Let's forecast mortality rate for next one year (52 weeks).

```{r}
fit.arima %>% forecast(h = 52) %>%  # h = "1 years"
  autoplot(flu_ts, level=NULL) +
  labs(y = "FluPos", title = "Weekly positive case in Canada using SARIMA")
```

## Simple Exponential Smoothing 

```{r, warning=FALSE}
fit.ets <- flu_ts %>% model(ETS(FluPos))
report(fit.ets)
```

```{r, warning=FALSE}
fit.ets %>% 
  forecast(h = "1 years") %>% 
  autoplot(flu_ts, level=NULL)+
  labs(title="Weekly flu positive case in Canada using ETS", y="FluPos")
```

## Neural Netwrok Model 

Now, we will use Neural network autoregression model to forecast mortality rate using `NNETAR()` function that fits an NNAR($p,P,k$)$_m$ model. If $p$ and $P$ are not specified, they are automatically selected.

```{r, echo=TRUE}
fit.nn <- flu_ts %>% model(NNETAR(FluPos))
fit.nn
```

The result provides a NNAR(6,1,4)[52] model for mortality rate. Here, the last 6 observations are used as predictors, and there are 4 neurons in the hidden layer.

Let's check the residual.

```{r, warning=FALSE}
gg_tsresiduals(fit.nn)
```

Let's forecast mortality rate for next one year (52 weeks).

```{r}
fit.nn %>% forecast(h="1 years", times=1) %>%
  autoplot(flu_ts, level=NULL) +
  labs(x = "Week", y = "FluPos", title = "Weekly flu positive case in Canada using NNAR")
```

## Prophet Model
Prophet is an open-source forecasting tool developed by Facebook for time series forecasting. Prophet model is available via the `fable.prophet` package. 

```{r, warning=FALSE}
fit.ph <- flu_ts %>% 
  model(prophet(FluPos ~ season(period = 52, order = 10)))
fit.ph |> gg_tsresiduals() # check residual
#components(fit.ph) %>% autoplot()
```

Let's forecast mortality rate for next one year (52 weeks).

```{r, echo=TRUE, warning=FALSE}
fit.ph %>% forecast(h = "1 years") %>% 
  autoplot(flu_ts, level=NULL) + 
  labs(x = "Week", y = "FluPos", title = "Weekly flu positive case in Canada using Prophet")
```

## Forecast accuracy: Comparing all models 

We can fit all model together in one function and compare them based on some accuracy measures. Then choose the best one and forecast based on the best model. 

```{r, warning=FALSE}
flu_fit <-  flu_ts %>%
  model(
    Seasonal_naive = SNAIVE(FluPos),
    Naive = NAIVE(FluPos),
    Mean = MEAN(FluPos),
    Arima = ARIMA(FluPos),
    ETS = ETS(FluPos),
    NNAR = NNETAR(FluPos),
    #Prophet = prophet(FluPos)
    Prophet = prophet(FluPos ~ season(period = 52, order = 10))
  )
```

We can now produce forecasts for next 1 years (52 weeks) using the fitted models.

```{r, warning=FALSE}
flu_fc <- flu_fit %>%
  forecast(h = "1 years", times=1)

flu_fc %>%
  autoplot(flu_ts, level = NULL) +
  labs(title = "Weekly flu positive case in Canada",
       y = "Number of positive cases") +
  guides(colour = guide_legend(title = "Forecast"))
```

Let's compare all models.

```{r}
accuracy(flu_fit)
```

Based on the accuracy measures (say, RMSE, MAE, MAPE, MASE), it is found that Neural Net and then ARIMA models provide better forecasting performance compare to other models.


# Time Series Regression

Now, we are going to do the time series regression models. We will forecast the weekly mortality rate based on some other predictor, say mean temperature of week, Google flu tend, trend of the data, any intervention effect (e.g. swine-flu effect) and so on. We need to assume that morality rate has a linear relationship with these predictors. 

First let's look at the time plot again. 

```{r}
peak_time <- flu_ts |> 
  filter(FluPos == max(FluPos, na.rm = TRUE)) |> 
  pull(index(flu_ts)) |> 
  as.Date()
flu_ts %>% autoplot(FluPos) +
  geom_vline(xintercept = peak_time, linetype = "dashed", color = "red")+
  annotate("text", x = peak_time + 500, y = 7500, label = "Swine-flu Peak", 
           vjust = 2, color = "red", angle = 0)
```

Now, let's look at the relationship among variables. 

```{r, fig.height=4, fig.width=8}
flu_ts %>%
  select(FluPos, tem_CA, GFT.Canada, week) %>% pivot_longer(-week) |>
  ggplot(aes(week, value, colour = name)) +
  geom_line() + facet_grid(name ~ ., scales = "free_y") +
  guides(colour = "none") + labs(y=" ")
```

Let's see the relation between weekly mortality rate and weekly mean temperature. 

```{r, echo=TRUE}
flu_ts %>%
  ggplot(aes(y = FluPos, x = GFT.Canada)) +
  labs(x = "GFT Trend", y = "Flu positive case in Canada") +
  geom_point() + geom_smooth(method = "lm", se = FALSE)
```

Let's fit the time series regression model using covariates/predictors, say swine-flu intervention effect, trend variable (already built in *fpp3* package as *trend()*)

```{r}
# create dummy for swine-flu intervention effect
flu_ts <- flu_ts |>
  mutate(swineflu=ifelse(Date<as.Date("2009-10-26"),0,1))

fit_flu <- flu_ts |>
  model(TSLM(FluPos ~ GFT.Canada+ tem_CA+ swineflu +trend()))
report(fit_flu)

# Check the fitted values
augment(fit_flu) |>
  ggplot(aes(x = week)) +
  geom_line(aes(y = FluPos, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = NULL,
    title = "Weekly flu positive case in Canada"
  ) +
  scale_colour_manual(values=c(Data="black",Fitted="#D55E00")) +
  guides(colour = guide_legend(title = NULL))
```

## Residual diagnostics

It is very important to do residual diagnostic after fitting the regression model so that we can verify the assumptions (residual's are uncorrelated, zero mean, constant variance, uncorrelated with other predictor).

```{r}
fit_flu |> gg_tsresiduals(lag=52)
``` 

\textcolor{red}{By looking at the auto correlation function of residuals, we can see still some correlation left in the residuals!} 

\textcolor{blue}{What to do then??}

\textcolor{blue}{Solution: we can use Dynamic regression model.}

## Dynamic regression models

```{r}
flu_ts %>%
  select(-Date) %>%
  gather(key='variable', value='value') %>%
  ggplot(aes(y=value, x=week, group=variable, colour=variable)) +
  geom_line() + facet_grid(variable ~ ., scales='free_y') +
  labs(y="",title ="Flu positive case in Canada") +
  guides(colour="none")
```  

```{r}
fit.dyn <- flu_ts %>% model(ARIMA(FluPos ~ GFT.Canada+ tem_CA+ swineflu +trend()))
report(fit.dyn)

# Check the fitted values
augment(fit.dyn) |>
  ggplot(aes(x = week)) +
  geom_line(aes(y = FluPos, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted")) +
  labs(y = NULL,
    title = "Flu positive case in Canada"
  ) +
  scale_colour_manual(values=c(Data="black",Fitted="#D55E00")) +
  guides(colour = guide_legend(title = NULL))

augment(fit.dyn) |>
  ggplot(aes(x = FluPos, y = .fitted)) +
  geom_point() +
  labs(
    y = "Fitted (predicted values)",
    x = "Data (actual values)",
    title = "Flu positive case in Canada"
  ) +
  geom_abline(intercept = 0, slope = 1)
```

## Residual diagnostics

Recall that, in dynamic regression we have two errors: regression error ($\eta_t,$ will show some correlation) and Arima error ($\epsilon_t,$ will show no significant correlation).

```{r, warning=FALSE}
# regression error
residuals(fit.dyn, type='regression') %>%
  gg_tsdisplay(.resid, plot_type = 'partial') +
  labs(title = "Regression errors")
# Arima error
residuals(fit.dyn, type='innovation') %>%
  gg_tsdisplay(.resid, plot_type = 'partial') +
  labs(title = "ARIMA errors")
```

\textcolor{blue}{Residuals seems white noise, means no significant correlation left!}

```{r}
augment(fit.dyn) |>
  features(.innov, ljung_box,lag = 52)
```

The results are not significant (i.e., the p-values are relatively large). Thus, we
can conclude that the residuals are not distinguishable from a white noise series.


\textbf{Comment:} Overall, it shows that the dynamic regression perform better than the time series linear  regression. 

# Interactive graphics for Time Series data: 

We are trying to developed interactive shiny graphics to address these issues for several of the most common time series data analyses. The interactive shiny graphics is used to generate an interactive visualization environment that contains several distinct graphics, many of which are updated in response to user input. These visualizations reduce the burden of exploratory analyses and can serve as a useful tool for the communication of results to non-statisticians.

## Link (still under working)

\textcolor{blue}{<https://syedrizvi05.shinyapps.io/TimeSeries/>}


# Acknowledgement: 

This document was prepared with the help of a research student, *Syed Jafar Rizvi*, MSc Student, Dept. of Community Health and Epidemiology, University of Saskatchewan. Fell free to knock Rizbi at *jafar.rizvi@usask.ca* if you have any question. 

